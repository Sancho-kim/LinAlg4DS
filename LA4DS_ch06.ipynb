{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Linear Algebra for Data Science\n",
        "## Mike X Cohen (sincxpress.com)\n",
        "### https://www.oreilly.com/library/view/practical-linear-algebra/9781098120603/\n",
        "\n",
        "#### Code for chapter 7"
      ],
      "metadata": {
        "id": "SbGFWGzkd44U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YOIjKOde7n_"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# setup animation\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "\n",
        "# to read an image from a url (io) and convert it to grayscale (color)\n",
        "from skimage import io,color\n",
        "# convolution\n",
        "from scipy.signal import convolve2d\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# NOTE: these lines define global figure properties used for publication.\n",
        "import matplotlib_inline.backend_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg') # display figures in vector format\n",
        "plt.rcParams.update({'font.size':14}) # set global font size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_bfQH6we_D7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpN43uq3_IVz"
      },
      "source": [
        "# Covariance matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb1un3n8_IYr"
      },
      "outputs": [],
      "source": [
        "# information about the data\n",
        "#https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime\n",
        "\n",
        "# raw data file\n",
        "#https://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data\n",
        "\n",
        "# dataset citation (see also above website for more):\n",
        "# Redmond, M. A. and A. Baveja: A Data-Driven Software Tool for Enabling Cooperative Information Sharing Among Police Departments. European Journal of Operational Research 141 (2002) 660-678."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9XfRwQ5_IbN"
      },
      "outputs": [],
      "source": [
        "# read the data into a pandas dataframe\n",
        "url  = 'https://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data'\n",
        "data = pd.read_csv(url,sep=',',header=None)\n",
        "\n",
        "# attach column labels (don't worry, I didn't type this all in by hand, lol)\n",
        "data.columns = [ 'state', 'county', 'community', 'communityname', 'fold', 'population', 'householdsize', 'racepctblack', 'racePctWhite',\n",
        "'racePctAsian', 'racePctHisp', 'agePct12t21', 'agePct12t29', 'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban', 'medIncome', 'pctWWage',\n",
        "'pctWFarmSelf', 'pctWInvInc', 'pctWSocSec', 'pctWPubAsst', 'pctWRetire', 'medFamInc', 'perCapInc', 'whitePerCap', 'blackPerCap', 'indianPerCap',\n",
        "'AsianPerCap', 'OtherPerCap', 'HispPerCap', 'NumUnderPov', 'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad', 'PctBSorMore', 'PctUnemployed', 'PctEmploy',\n",
        "'PctEmplManu', 'PctEmplProfServ', 'PctOccupManu', 'PctOccupMgmtProf', 'MalePctDivorce', 'MalePctNevMarr', 'FemalePctDiv', 'TotalPctDiv', 'PersPerFam', 'PctFam2Par',\n",
        "'PctKids2Par', 'PctYoungKids2Par', 'PctTeen2Par', 'PctWorkMomYoungKids', 'PctWorkMom', 'NumIlleg', 'PctIlleg', 'NumImmig', 'PctImmigRecent', 'PctImmigRec5',\n",
        "'PctImmigRec8', 'PctImmigRec10', 'PctRecentImmig', 'PctRecImmig5', 'PctRecImmig8', 'PctRecImmig10', 'PctSpeakEnglOnly', 'PctNotSpeakEnglWell', 'PctLargHouseFam', 'PctLargHouseOccup',\n",
        "'PersPerOccupHous', 'PersPerOwnOccHous', 'PersPerRentOccHous', 'PctPersOwnOccup', 'PctPersDenseHous', 'PctHousLess3BR', 'MedNumBR', 'HousVacant', 'PctHousOccup', 'PctHousOwnOcc',\n",
        "'PctVacantBoarded', 'PctVacMore6Mos', 'MedYrHousBuilt', 'PctHousNoPhone', 'PctWOFullPlumb', 'OwnOccLowQuart', 'OwnOccMedVal', 'OwnOccHiQuart', 'RentLowQ', 'RentMedian',\n",
        "'RentHighQ', 'MedRent', 'MedRentPctHousInc', 'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg', 'NumInShelters', 'NumStreet', 'PctForeignBorn', 'PctBornSameState', 'PctSameHouse85',\n",
        "'PctSameCity85', 'PctSameState85', 'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps', 'LemasSwFTFieldPerPop', 'LemasTotalReq', 'LemasTotReqPerPop', 'PolicReqPerOffic', 'PolicPerPop',\n",
        "'RacialMatchCommPol', 'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', 'PctPolicAsian', 'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz', 'PolicAveOTWorked', 'LandArea',\n",
        "'PopDens', 'PctUsePubTrans', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr', 'LemasGangUnitDeploy', 'LemasPctOfficDrugUn', 'PolicBudgPerPop', 'ViolentCrimesPerPop',\n",
        " ]\n",
        "\n",
        "# have a look at the data\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_bDpoRkLCsK"
      },
      "outputs": [],
      "source": [
        "# extract only the numeric data\n",
        "numberDataset = data._get_numeric_data()\n",
        "\n",
        "# drop a few additional columns, and convert to a numpy array\n",
        "dataMat = numberDataset.drop(['state','fold'],axis=1).values\n",
        "dataMat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMzgqCG8PeGR"
      },
      "outputs": [],
      "source": [
        "# compute the mean of each data feature\n",
        "datamean = np.mean(dataMat,axis=0)\n",
        "\n",
        "# mean-center the data using broadcasting\n",
        "dataMatM = dataMat - datamean\n",
        "\n",
        "# confirm that any given feature has mean=0 (or very close...)\n",
        "print(np.mean(dataMatM[:,0]))\n",
        "\n",
        "\n",
        "# Now to compute the covariance matrix\n",
        "covMat = dataMatM.T @ dataMatM  # data matrix times its transpose\n",
        "covMat /= (dataMatM.shape[0]-1) # divide by N-1\n",
        "\n",
        "# dynamic color scaling\n",
        "clim = np.max(np.abs(covMat)) * .2\n",
        "\n",
        "# and show it\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(covMat,vmin=-clim,vmax=clim,cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.title('Data covariance matrix')\n",
        "plt.savefig('Figure_07_01.png',dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRILNLICQnMJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HcSs2c0ubhB"
      },
      "source": [
        "# Transformation matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM0pIzccuboF"
      },
      "outputs": [],
      "source": [
        "# Pure rotation matrix\n",
        "\n",
        "# angle to rotate by\n",
        "th = np.pi/5\n",
        "\n",
        "# transformation matrix\n",
        "T = np.array([\n",
        "              [ np.cos(th),np.sin(th)],\n",
        "              [-np.sin(th),np.cos(th)]\n",
        "            ])\n",
        "\n",
        "\n",
        "# original dots are a vertical line\n",
        "x = np.linspace(-1,1,20)\n",
        "origPoints = np.vstack( (np.zeros(x.shape),x) )\n",
        "\n",
        "\n",
        "# apply the transformation\n",
        "transformedPoints = T @ origPoints\n",
        "\n",
        "\n",
        "# plot the points\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(origPoints[0,:],origPoints[1,:],'ko',label='Original')\n",
        "plt.plot(transformedPoints[0,:],transformedPoints[1,:],'s',color=[.7,.7,.7],label='Transformed')\n",
        "\n",
        "plt.axis('square')\n",
        "plt.xlim([-1.2,1.2])\n",
        "plt.ylim([-1.2,1.2])\n",
        "plt.legend()\n",
        "plt.title(f'Rotation by {np.rad2deg(th):.0f} degrees.')\n",
        "plt.savefig('Figure_07_02.png',dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9Tdi8QNubrU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jew2fiOg3aW0"
      },
      "source": [
        "# Animating transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWAat1Be03Ty"
      },
      "outputs": [],
      "source": [
        "# function to update the axis on each iteration\n",
        "def aframe(ph):\n",
        "\n",
        "  # create the transformation matrix\n",
        "  T = np.array([\n",
        "                 [  1, 1-ph ],\n",
        "                 [  0, 1    ]\n",
        "                ])\n",
        "\n",
        "  # apply the transformation to the points using matrix multiplication\n",
        "  P = T@points\n",
        "\n",
        "  # update the dots\n",
        "  plth.set_xdata(P[0,:])\n",
        "  plth.set_ydata(P[1,:])\n",
        "\n",
        "  # export the plot handles\n",
        "  return plth\n",
        "\n",
        "\n",
        "# define XY points\n",
        "theta  = np.linspace(0,2*np.pi,100)\n",
        "points = np.vstack((np.sin(theta),np.cos(theta)))\n",
        "\n",
        "\n",
        "# setup figure\n",
        "fig,ax = plt.subplots(1,figsize=(12,6))\n",
        "plth,  = ax.plot(np.cos(x),np.sin(x),'ko')\n",
        "ax.set_aspect('equal')\n",
        "ax.set_xlim([-2,2])\n",
        "ax.set_ylim([-2,2])\n",
        "\n",
        "# define values for transformation (note: clip off the final point for a smooth animation loop)\n",
        "phi = np.linspace(-1,1-1/40,40)**2\n",
        "\n",
        "# run animation!\n",
        "animation.FuncAnimation(fig, aframe, phi, interval=100, repeat=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UsNXuZEenOrM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoxwODIAnOyc"
      },
      "source": [
        "# Image convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATWcNxtt_H6c"
      },
      "outputs": [],
      "source": [
        "# image\n",
        "imgN  = 20\n",
        "image = np.random.randn(imgN,imgN)\n",
        "\n",
        "# convolution kernel\n",
        "kernelN = 7\n",
        "Y,X     = np.meshgrid(np.linspace(-3,3,kernelN),np.linspace(-3,3,kernelN))\n",
        "kernel  = np.exp( -(X**2+Y**2)/7 )\n",
        "kernel  = kernel / np.sum(kernel) # normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNT0xdEv_Uj9"
      },
      "outputs": [],
      "source": [
        "# now for the convolution\n",
        "halfKr = kernelN//2\n",
        "convoutput = np.zeros((imgN+kernelN-1,imgN+kernelN-1))\n",
        "\n",
        "imagePad = np.zeros(convoutput.shape)\n",
        "imagePad[halfKr:-halfKr:1,halfKr:-halfKr:1] = image\n",
        "\n",
        "\n",
        "# double for-loop over rows and columns (width and height of picture)\n",
        "for rowi in range(halfKr,imgN+halfKr):\n",
        "  for coli in range(halfKr,imgN+halfKr):\n",
        "\n",
        "    # cut out a piece of the image\n",
        "    pieceOfImg = imagePad[rowi-halfKr:rowi+halfKr+1:1,coli-halfKr:coli+halfKr+1:1]\n",
        "\n",
        "    # dot product: element-wise multiply and sum\n",
        "    dotprod = np.sum( pieceOfImg*kernel )\n",
        "\n",
        "    # store the result for this pixel\n",
        "    convoutput[rowi,coli] = dotprod\n",
        "\n",
        "\n",
        "# trim off edges\n",
        "convoutput = convoutput[halfKr:-halfKr:1,halfKr:-halfKr:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZxS_TZc_IAo"
      },
      "outputs": [],
      "source": [
        "# using scipy\n",
        "convoutput2 = convolve2d(image,kernel,mode='same')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Btnvz4wK_IDl"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(2,2,figsize=(8,8))\n",
        "\n",
        "ax[0,0].imshow(image)\n",
        "ax[0,0].set_title('Image')\n",
        "\n",
        "ax[0,1].imshow(kernel)\n",
        "ax[0,1].set_title('Convolution kernel')\n",
        "\n",
        "ax[1,0].imshow(convoutput)\n",
        "ax[1,0].set_title('Manual convolution')\n",
        "\n",
        "ax[1,1].imshow(convoutput2)\n",
        "ax[1,1].set_title(\"Scipy's convolution\")\n",
        "\n",
        "# for i in ax.flatten(): i.axis('off')\n",
        "\n",
        "plt.savefig('Figure_07_04b.png',dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqwT501n_IGt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBadnRLzE8rY"
      },
      "outputs": [],
      "source": [
        "# read a pic from the web\n",
        "bathtub = io.imread('https://upload.wikimedia.org/wikipedia/commons/6/61/De_nieuwe_vleugel_van_het_Stedelijk_Museum_Amsterdam.jpg')\n",
        "\n",
        "# check the size\n",
        "print(bathtub.shape)\n",
        "\n",
        "# let's see what the famous Bathtub Museum looks like\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.imshow(bathtub)\n",
        "plt.savefig('Figure_07_05a.png',dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# transform image to 2D for convenience (not necessary for convolution!)\n",
        "bathtub2d = color.rgb2gray(bathtub)\n",
        "\n",
        "# check the size again\n",
        "print(bathtub2d.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzVxf5US_IMt"
      },
      "outputs": [],
      "source": [
        "# convolution kernel\n",
        "kernelN = 29 # a bit bigger than in the previous example... feel free to change this parameter!\n",
        "Y,X     = np.meshgrid(np.linspace(-3,3,kernelN),np.linspace(-3,3,kernelN))\n",
        "kernel  = np.exp( -(X**2+Y**2)/20 )\n",
        "kernel  = kernel / np.sum(kernel) # normalize the kernel to integrate to 1, which preserves the numerical scale of the image.\n",
        "\n",
        "\n",
        "# smoothing via Gaussian convolution\n",
        "smooth_bathtub = convolve2d(bathtub2d,kernel,mode='same')\n",
        "\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.imshow(smooth_bathtub,cmap='gray')\n",
        "plt.savefig('Figure_07_05b.png',dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wVsAFEyLC8E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM-barvQLC-x"
      },
      "source": [
        "# Exercise 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiI-EwozLCvN"
      },
      "outputs": [],
      "source": [
        "# Diagonal matrix of inverse standard deviations\n",
        "variances = np.diag(covMat) # variances are the diagonals of a covariance\n",
        "standard_devs = np.sqrt( variances )\n",
        "S = np.diag( 1/standard_devs )\n",
        "\n",
        "# you can also do this in one line:\n",
        "#S = np.diag( 1/np.sqrt(np.diag(covMat)) )\n",
        "\n",
        "\n",
        "# compute the correlation matrix\n",
        "corrMat = S @ covMat @ S\n",
        "\n",
        "\n",
        "# and show the matrices\n",
        "fig,axs = plt.subplots(1,2,figsize=(13,6))\n",
        "h1 = axs[0].imshow(covMat,vmin=-clim,vmax=clim,cmap='gray')\n",
        "axs[0].set_title('Data covariance matrix',fontweight='bold')\n",
        "\n",
        "h2 = axs[1].imshow(corrMat,vmin=-.5,vmax=.5,cmap='gray')\n",
        "axs[1].set_title('Data correlation matrix',fontweight='bold')\n",
        "\n",
        "fig.colorbar(h1,ax=axs[0],fraction=.045)\n",
        "fig.colorbar(h2,ax=axs[1],fraction=.045)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('Figure_07_06.png',dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXidxhGPojEy"
      },
      "outputs": [],
      "source": [
        "# a bit of code to explore specific pairs of correlations\n",
        "\n",
        "# here list two indices into the correlation matrix (row, col)\n",
        "i,j = 43,17\n",
        "\n",
        "# the printed tuple will show the correlation and the pairs of variables\n",
        "corrMat[i,j], data.columns[i], data.columns[j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WCP5_ZlS3_v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tCv-E5ssOuV"
      },
      "source": [
        "# Exercise 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9xW7Rusk7os"
      },
      "outputs": [],
      "source": [
        "# numpy's correlation function (note transposing the matrix!)\n",
        "corrMat_np = np.corrcoef(dataMat.T)\n",
        "\n",
        "\n",
        "# and show it\n",
        "fig,axs = plt.subplots(1,3,figsize=(13,6))\n",
        "h1 = axs[0].imshow(corrMat,vmin=-.5,vmax=.5,cmap='gray')\n",
        "axs[0].set_title('My correlation matrix',fontweight='bold')\n",
        "\n",
        "h2 = axs[1].imshow(corrMat_np,vmin=-.5,vmax=.5,cmap='gray')\n",
        "axs[1].set_title(\"Numpy's correlation matrix\",fontweight='bold')\n",
        "\n",
        "h3 = axs[2].imshow(corrMat_np-corrMat,vmin=-.0005,vmax=.0005,cmap='gray')\n",
        "axs[2].set_title('Difference matrix',fontweight='bold')\n",
        "\n",
        "fig.colorbar(h1,ax=axs[0],fraction=.045)\n",
        "fig.colorbar(h2,ax=axs[1],fraction=.045)\n",
        "fig.colorbar(h3,ax=axs[2],fraction=.045)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('Figure_07_07.png',dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mv-cJZY9LCye"
      },
      "outputs": [],
      "source": [
        "??np.corrcoef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR2vPqFMmU55"
      },
      "outputs": [],
      "source": [
        "??np.cov"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hoRmwuUtNSGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFOZC7mmOCH4"
      },
      "source": [
        "# Exercise 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4TiPCLrubk-"
      },
      "outputs": [],
      "source": [
        "# Transformation matrix\n",
        "T = np.array([\n",
        "              [1,.5],\n",
        "              [0,.5]\n",
        "            ])\n",
        "\n",
        "\n",
        "# define the set of points (a circle)\n",
        "theta = np.linspace(0,2*np.pi-2*np.pi/20,20)\n",
        "origPoints = np.vstack( (np.cos(theta),np.sin(theta)) )\n",
        "\n",
        "# apply transformation\n",
        "transformedPoints = T @ origPoints\n",
        "\n",
        "\n",
        "# plot the points\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(origPoints[0,:],origPoints[1,:],'ko',label='Original')\n",
        "plt.plot(transformedPoints[0,:],transformedPoints[1,:],'s',\n",
        "         color=[.7,.7,.7],label='Transformed')\n",
        "\n",
        "plt.axis('square')\n",
        "plt.xlim([-2,2])\n",
        "plt.ylim([-2,2])\n",
        "plt.legend()\n",
        "plt.savefig('Figure_07_08.png',dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBo0PjEbWo03"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42h5-_HYOuW1"
      },
      "source": [
        "# Exercise 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uYT5rLj3aZK"
      },
      "outputs": [],
      "source": [
        "# function to draw the plots\n",
        "def aframe(ph):\n",
        "\n",
        "  # create the transformation matrix\n",
        "  T = np.array([ [  1-ph/3,0 ],\n",
        "                 [  0,ph   ] ])\n",
        "\n",
        "  # apply the transformation to the points using matrix multiplication\n",
        "  P1 = T@Y1\n",
        "  P2 = T@Y2\n",
        "\n",
        "  # update the lower/upper lines\n",
        "  plth1.set_xdata(P1[0,:])\n",
        "  plth1.set_ydata(P1[1,:])\n",
        "\n",
        "  plth2.set_xdata(P2[0,:])\n",
        "  plth2.set_ydata(P2[1,:])\n",
        "\n",
        "  # export the plot handles\n",
        "  return (plth1,plth2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS3CrcO9o1KF"
      },
      "outputs": [],
      "source": [
        "# define XY points\n",
        "th = np.linspace(0,2*np.pi,100) # th = theta (angles)\n",
        "Y1 = np.vstack((th,np.cos(th)))\n",
        "Y2 = np.vstack((th,np.sin(th)))\n",
        "\n",
        "\n",
        "# setup figure\n",
        "fig,ax = plt.subplots(1,figsize=(12,6))\n",
        "\n",
        "plth1, = ax.plot(Y1[0,:],Y1[1,:],'ko')\n",
        "plth2, = ax.plot(Y2[0,:],Y2[1,:],'s',color=[.7,.7,.7])\n",
        "ax.set_ylim([-2,2])\n",
        "\n",
        "\n",
        "# define phases and run animation\n",
        "phi = 1-np.linspace(-1,1-1/40,40)**2\n",
        "animation.FuncAnimation(fig, aframe, phi, interval=50, repeat=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5hfS0iB_RlAg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m134qWL_TBzA"
      },
      "source": [
        "# Exercise 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk625TaYTB3h"
      },
      "outputs": [],
      "source": [
        "# initialize smoothed image\n",
        "smooth_bathtub = np.zeros(bathtub.shape)\n",
        "\n",
        "# smooth each layer individually\n",
        "for i in range(smooth_bathtub.shape[2]):\n",
        "  smooth_bathtub[:,:,i] = convolve2d(bathtub[:,:,i],kernel,mode='same')\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.imshow(smooth_bathtub.astype(np.uint8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvmZjYNcDEcH"
      },
      "outputs": [],
      "source": [
        "# check data types\n",
        "print( smooth_bathtub.dtype )\n",
        "print( smooth_bathtub.astype(np.uint8).dtype )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJmM0IIY2OFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Figure 6"
      ],
      "metadata": {
        "id": "te0x7V6U2ODU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLgP81G5Cb6y"
      },
      "outputs": [],
      "source": [
        "# layer-specific kernel widths\n",
        "kernelN = 31\n",
        "kernelWidths = [.5,5,50]\n",
        "\n",
        "\n",
        "# initialize smoothed image\n",
        "smooth_bathtub = np.zeros(bathtub.shape)\n",
        "\n",
        "# to show the kernels\n",
        "_,axs = plt.subplots(1,3,figsize=(12,6))\n",
        "\n",
        "# smooth each layer individually\n",
        "for i in range(smooth_bathtub.shape[2]):\n",
        "\n",
        "  # create kernel\n",
        "  Y,X     = np.meshgrid(np.linspace(-3,3,kernelN),np.linspace(-3,3,kernelN))\n",
        "  kernel  = np.exp( -(X**2+Y**2) / kernelWidths[i] )\n",
        "  kernel  = kernel / np.sum(kernel) # normalize\n",
        "\n",
        "  # visualize the kernels\n",
        "  axs[i].imshow(kernel,cmap='gray')\n",
        "  axs[i].set_title(f'Width: {kernelWidths[i]} ({\"RGB\"[i]} channel)')\n",
        "\n",
        "  # now run convolution\n",
        "  smooth_bathtub[:,:,i] = convolve2d(bathtub[:,:,i],kernel,mode='same')\n",
        "\n",
        "plt.savefig('Figure_07_10.png',dpi=300)\n",
        "plt.show() # close the kernels figure\n",
        "\n",
        "\n",
        "# show the smoothed image\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.imshow(smooth_bathtub.astype(np.uint8))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7K6uqUnTB67"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAHNAwvYRkeM"
      },
      "source": [
        "# Exercise 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SnUUHPm7xQE"
      },
      "outputs": [],
      "source": [
        "# Create two feature-detection kernels\n",
        "\n",
        "# vertical kernel\n",
        "VK = np.array([ [1,0,-1],\n",
        "                [1,0,-1],\n",
        "                [1,0,-1] ])\n",
        "\n",
        "# horizontal kernel\n",
        "HK = np.array([ [ 1, 1, 1],\n",
        "                [ 0, 0, 0],\n",
        "                [-1,-1,-1] ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCooGt9PiNb6"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(2,2,figsize=(16,8))\n",
        "\n",
        "ax[0,0].imshow(VK,cmap='gray')\n",
        "ax[0,0].set_title('Vertical kernel')\n",
        "ax[0,0].set_yticks(range(3))\n",
        "\n",
        "ax[0,1].imshow(HK,cmap='gray')\n",
        "ax[0,1].set_title('Horizontal kernel')\n",
        "ax[0,1].set_yticks(range(3))\n",
        "\n",
        "# run convolution and show the result\n",
        "convres = convolve2d(bathtub2d,VK,mode='same')\n",
        "ax[1,0].imshow(convres,cmap='gray',vmin=0,vmax=.01)\n",
        "ax[1,0].axis('off')\n",
        "\n",
        "convres = convolve2d(bathtub2d,HK,mode='same')\n",
        "ax[1,1].imshow(convres,cmap='gray',vmin=0,vmax=.01)\n",
        "ax[1,1].axis('off')\n",
        "\n",
        "plt.savefig('Figure_07_11.png',dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uMwMUuotNWNs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "LA4DS_ch07.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
